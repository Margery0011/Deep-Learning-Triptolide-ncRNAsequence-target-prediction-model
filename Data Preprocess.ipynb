{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c795cc64-b658-4914-b799-f2e33f4121c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e81235-ad56-47b3-801d-6da234eb559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a31b70-da10-42b8-87f4-f6196cb9e076",
   "metadata": {},
   "source": [
    "## Read file type: read name and corresponding sequence\n",
    ">hsa-let-7a-5p MIMAT0000062 Homo sapiens let-7a-5p\n",
    "\n",
    "UGAGGUAGUAGGUUGUAUAGUU\n",
    "\n",
    ">hsa-let-7a-3p MIMAT0004481 Homo sapiens let-7a-3p\n",
    "\n",
    "CUAUACAAUCUACUGUCUUUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b88e1d-ee30-4bbb-9e07-17161312aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequence(file):\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    data = [line for line in lines if line != '\\n']\n",
    "    seq_line = data[1::2]#\n",
    "    name_lines = data[0::2]\n",
    "    idx = [i for i in range(len(seq_lines)) if len(seq_lines[i]) < 25]\n",
    "    seq = [seq_lines[i].strip() for i in idx] # .strip() : remove spaces\n",
    "    name = [name_lines[i].strip().split()[-1] for i in idx]\n",
    "    return seq, name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d768c715-9282-4c5a-9f31-1a9cc3c9d3ef",
   "metadata": {},
   "source": [
    " \n",
    " ### Input: file path\"\" Output: sequence seq[\"\"], name name[\"\"]\n",
    " \n",
    " - read the sequence and name line by line\n",
    " - add index (the maximum sequence is 25)\n",
    " - there will be blank lines in the file, remove blank lines\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b429904e-2532-4837-a8f7-4787efd28d16",
   "metadata": {},
   "source": [
    "## Read the type of the file: read the name and the corresponding degree of association, select the highest degree of association\n",
    "\n",
    "excel  sheet “result”\n",
    "\n",
    "miR-4755-3p.pdb\t3\t-7.6\n",
    "\n",
    "miR-8055.pdb\t3\t-7.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3cceae7-329f-4efd-abc6-1810a0e2fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_affinity(file):\n",
    "    # Read Files\n",
    "    sheet = pds.read_excel(file, sheet_name='result')\n",
    "    # Chose rows where the corresponding degrees are \n",
    "    affinity_t = sheet.value[:, 2],
    "    affinity_t = [a for a in affinity_t]\n",
    "    # Read the row with the name\n",
    "    name_t = sheet.values[:, 0]",
    "    name_t = [n.split('.')[0] for n in name_t]#Split the element before "." and read\n",
    "    affi = []#The last returned associativity\n",
    "    name = []#The last returned Name\n",
    "    idx_same = []\n",
    "    for i,n in enumerate(name_t):\n",
    "        #If the name never occurs, add it to the returned names and find the largest associativity\n",
    "        if i not in idx_same:\n",
    "            affi_t = [affinity_t[i]]\n",
    "            \n",
    "            # After traversing each name, compare all the associative degrees, and add the subscript of the repeated name to idx_same, and then no longer traverse\n",
    "            for j in range(i + 1, len(name_t)):\n",
    "                if name_t[j] == n :\n",
    "                    affi_t.append(affinity_t[j])\n",
    "                    idx_sa,e.append(j)\n",
    "            affi.append(sorted(affi_t)[0])\n",
    "            name.append(n)\n",
    "        else:\n",
    "            continue\n",
    "    return affi,name\n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb88844-67ae-4d72-9a66-33ff7e5633fa",
   "metadata": {},
   "source": [
    "### Input: file path\"\" Output: associative degree affi[float], name name[\"\"], one-to-one correspondence according to the subscript\n",
     "\n",
     "- read the line where the associative degree is located and the line where the name is located and return to the list\n",
     "- pick the highest associative enumerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3575e2-fe57-4e53-97cb-755e950c9b18",
   "metadata": {},
   "source": [
    "## As with the previous function, the associativity is averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d23631-6fc6-4cfa-817c-6dee1e65cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_affinity_mean(file):\n",
    "    sheet = pds.read_excel(file, sheet_name = 'result')\n",
    "    affinity_t = sheet.values[:, 2]\n",
    "    affinity_t = [a for a in affinity_t]\n",
    "    name_t = sheet.values[:, 0]\n",
    "    name_t = [n.split('.')[0] for n in name_t]\n",
    "    num = sheet.values[:, 1]\n",
    "    num = [n for n in num]\n",
    "    affi = []\n",
    "    name = []\n",
    "    idx_same = []\n",
    "    for i, n in enumerate(name_t):\n",
    "        if i not in idx_same:\n",
    "            affi_t = [affinity_t[i]]\n",
    "            num_t = num[i]\n",
    "            for j in range(i + 1, len(name_t)):\n",
    "                if name_t[j] == n:\n",
    "                    affi_t.append(affinity_t[j])\n",
    "                    idx_same.append(j)\n",
    "                    num_t += num[j]\n",
    "            affi.append(sum(affi_t)/num_t)\n",
    "            name.append(n)\n",
    "        else:\n",
    "            continue\n",
    "    return affi, name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2f8a2-268d-4bf8-9149-63e82ece217a",
   "metadata": {},
   "source": [
    "## Read associativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dddad69e-0b77-4dac-9856-787c5b45ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_affinity_rich(file):\n",
    "    affinity_t = sheet.values[:, 2]\n",
    "    affinity_t = [a for a in affinity_t]\n",
    "    name_t = sheet.values[:, 0]\n",
    "    name_t = [n.split('.')[0] for n in name_t]\n",
    "    max_affi = max(affinity_t)\n",
    "    min_affi = min(affinity_t)\n",
    "    affi = []\n",
    "    name = []\n",
    "    idx_same = []\n",
    "    for i, n in enumerate(name_t):\n",
    "        if i not in idx_name:\n",
    "            affi_t = [affinity_t[i]]\n",
    "            for j in range(i + 1, len(name_t)):\n",
    "                if name_t[j] == n:\n",
    "                    affi_t.append(affinity_t[j])\n",
    "                    idx_same.append(j)\n",
    "            affi_sorted = sorted(affi_t)\n",
    "            if (affi_sorted[0]-min_affi)/(max_affi-min_affi) > 0.75:\n",
    "                for _ in range(6):\n",
    "                    for af in affi_sorted:\n",
    "                        affi.append(af)\n",
    "                        name.append(n)\n",
    "            elif (affi_sorted[0] - min_affi) / (max_affi - min_affi) < 0.25:\n",
    "                for _ in range(10):\n",
    "                    for af in affi_sorted:\n",
    "                        affi.append(af)\n",
    "                        name.append(n)\n",
    "            elif (affi_sorted[0]-min_affi)/(max_affi-min_affi) > 0.6:\n",
    "                for _ in range(2):\n",
    "                    for af in affi_sorted:\n",
    "                        affi.append(af)\n",
    "                        name.append(n)\n",
    "            elif (affi_sorted[0] - min_affi) / (max_affi - min_affi) < 0.4:\n",
    "                for _ in range(2):\n",
    "                    for af in affi_sorted:\n",
    "                        affi.append(af)\n",
    "                        name.append(n)\n",
    "            else:\n",
    "                for af in affi_sorted:\n",
    "                    affi.append(af)\n",
    "                    name.append(n)\n",
    "        else:\n",
    "            continue\n",
    "    return affi, name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454323e6-3a07-4a85-9519-608b49985571",
   "metadata": {},
   "source": [
    "    Because the associativity is normally distributed, the sample with the middle associativity will be much more probable than the two sides\n",
     " When training the neural network, it will be more average according to the probability, so the degree of association should be expanded according to the probability of normal distribution\n",
     " makes its probability distribution tend to be uniform\n",
     "Remember to record the name at the same time when recording the degree of association, so that the lengths of the two lists can be one-to-one correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94069314-74c7-4cd8-9121-f6ef5b199ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_affinity_smooth(file):\n",
    "    \"\"\"\n",
    "        Read the binding degree, but because the binding degree is normally distributed, the sample with the intermediate binding degree will be much larger than the probability of both sides\n",
     " When training the neural network, it will be more average according to the probability, so the degree of association should be expanded according to the normal distribution and probability\n",
     " makes its probability distribution tend to be uniform\n",
     " Remember to record the name at the same time when recording the degree of association, so that the lengths of the two lists can be one-to-one correspondence\n",
     "Enrichment is done differently\n",
    "        \"\"\"\n",
    "    sheet = pds.read_excel(file, sheet_name='result')\n",
    "    affinity_t = sheet.values[:, 2]\n",
    "    affinity_t = [a for a in affinity_t]\n",
    "    name_t = sheet.values[:, 0]\n",
    "    name_t = [n.split('.')[0] for n in name_t]\n",
    "    max_affi = max(affinity_t)\n",
    "    min_affi = min(affinity_t)\n",
    "    affi = []\n",
    "    name = []\n",
    "    idx_same = []\n",
    "    for i, n in enumerate(name_t):\n",
    "        if i not in idx_same:\n",
    "            affi_t = [affinity_t[i]]\n",
    "            for j in range(i + 1, len(name_t)):\n",
    "                if name_t[j] == n:\n",
    "                    affi_t.append(affinity_t[j])\n",
    "                    idx_same.append(j)\n",
    "            affi_sorted = sorted(affi_t)\n",
    "            if ((affi_sorted[0]-min_affi)/(max_affi-min_affi) > 0.7) | \\\n",
    "                    ((affi_sorted[0]-min_affi)/(max_affi-min_affi) < 0.35):\n",
    "                for af in affi_sorted:\n",
    "                    affi.append(af)\n",
    "                    name.append(n)\n",
    "            elif ((affi_sorted[0]-min_affi)/(max_affi-min_affi) > 0.55) | \\\n",
    "                    ((affi_sorted[0]-min_affi)/(max_affi-min_affi) < 0.45):\n",
    "                for af in affi_sorted[:len(affi_sorted) // 2]:\n",
    "                    affi.append(af)\n",
    "                    name.append(n)\n",
    "            else:\n",
    "                affi.append(sorted(affi_t)[0])\n",
    "                name.append(n)\n",
    "        else:\n",
    "            continue\n",
    "    return affi, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7743a8cc-4952-4cee-9785-edcba25ef23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_search_smooth(seq, name_seq, affi, name_affi):\n",
    "    \"\"\"\n",
    "    seq_res = []\n",
    "    affi_res = []\n",
    "    name_res = []\n",
    "    name_t = [n for n in name_seq if n in name_affi]\n",
    "    for name in name_t:\n",
    "        idx = [i for i, v in enumerate(name_affi) if v == name]\n",
    "        for i in idx:\n",
    "            name_res.append(name)\n",
    "            seq_res.append(seq[name_seq.index(name)])\n",
    "            affi_res.append(affi[i])\n",
    "\n",
    "    return seq_res, affi_res, name_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "970c6543-9718-42f4-b5e2-ceb90432ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mi(seq_file, affi_file):\n",
    "    affi, name_affi = load_affinity(affi_file)\n",
    "    seq, name_seq = load_sequence(seq_file)\n",
    "    seq_res, affi_res, name_res = cross_search(seq, name_seq, affi, name_affi)\n",
    "    return seq_res, affi_res, name_res\n",
    "\n",
    "\n",
    "def load_mi_mean(seq_file, affi_file):\n",
    "    affi, name_affi = load_affinity_mean(affi_file)\n",
    "    seq, name_seq = load_sequence(seq_file)\n",
    "    seq_res, affi_res, name_res = cross_search(seq, name_seq, affi, name_affi)\n",
    "    return seq_res, affi_res, name_res\n",
    "\n",
    "\n",
    "def load_mi_smooth(seq_file, affi_file):\n",
    "    affi, name_affi = load_affinity_smooth(affi_file)\n",
    "    seq, name_seq = load_sequence(seq_file)\n",
    "    seq_res, affi_res, name_res = cross_search_smooth(seq, name_seq, affi, name_affi)\n",
    "    return seq_res, affi_res, name_res\n",
    "\n",
    "\n",
    "def load_mi_rich(seq_file, affi_file):\n",
    "    affi, name_affi = load_affinity_rich(affi_file)\n",
    "    seq, name_seq = load_sequence(seq_file)\n",
    "    seq_res, affi_res, name_res = cross_search_smooth(seq, name_seq, affi, name_affi)\n",
    "    return seq_res, affi_res, name_res\n",
    "\n",
    "\n",
    "def load_pi(addr):\n",
    "    with open(addr, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    data = [line for line in lines if line != '\\n']\n",
    "    seq = data[1::2]\n",
    "    seq = [s.strip() for s in seq]\n",
    "    name = data[0::2]\n",
    "    name = [s.strip().split('|')[0] for s in name]\n",
    "    name_pi = []\n",
    "    for n in name:\n",
    "        if n not in name_pi:\n",
    "            name_pi.append(n)\n",
    "    seq_pi = [seq[name.index(n)] for n in name_pi]\n",
    "    return seq_pi, name_pi\n",
    "\n",
    "\n",
    "def check(seq, affi, name):\n",
    "    with open('homo-miRNA.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    data = [line for line in lines if line != '\\n']\n",
    "    seq_lines = data[1::2]\n",
    "    name_lines = data[0::2]\n",
    "    sheet = pds.read_excel('original.xls', sheet_name='result')\n",
    "    affinity_t = sheet.values[:, 2]\n",
    "    affinity_t = [a for a in affinity_t]\n",
    "    name_t = sheet.values[:, 0]\n",
    "    name_t = [n.split('.')[0] for n in name_t]\n",
    "    if (affi == affinity_t[name_t.index(name+'.pdb')]) & (seq == seq_lines[name_lines.index(name)]):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61afcebb-e850-4773-a0db-925a3a02c8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades = [70, 100, 97, 70, 85, 100, 400, 200, 32]\n",
    "grades.index(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1286e04d-7037-4b9f-88da-fe14d8a2dea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades.index(100,3,8)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97739b7-7f75-49c3-baf3-f4b1a9341de3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e916cee2b9d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'seq' is not defined"
     ]
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f49c37-7428-4849-984f-e396ea2533a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
