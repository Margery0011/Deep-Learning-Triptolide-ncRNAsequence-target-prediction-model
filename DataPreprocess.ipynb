{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c795cc64-b658-4914-b799-f2e33f4121c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e81235-ad56-47b3-801d-6da234eb559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a31b70-da10-42b8-87f4-f6196cb9e076",
   "metadata": {},
   "source": [
    "## 读取文件的类型 ：读取名字和对应的序列\n",
    ">hsa-let-7a-5p MIMAT0000062 Homo sapiens let-7a-5p\n",
    "\n",
    "UGAGGUAGUAGGUUGUAUAGUU\n",
    "\n",
    ">hsa-let-7a-3p MIMAT0004481 Homo sapiens let-7a-3p\n",
    "\n",
    "CUAUACAAUCUACUGUCUUUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b88e1d-ee30-4bbb-9e07-17161312aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequence(file):\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    data = [line for line in lines if line != '\\n']\n",
    "    seq_line = data[1::2]#\n",
    "    name_lines = data[0::2]\n",
    "    idx = [i for i in range(len(seq_lines)) if len(seq_lines[i]) < 25]\n",
    "    seq = [seq_lines[i].strip() for i in idx] # .strip() : remove spaces\n",
    "    name = [name_lines[i].strip().split()[-1] for i in idx]\n",
    "    return seq, name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d768c715-9282-4c5a-9f31-1a9cc3c9d3ef",
   "metadata": {},
   "source": [
    " \n",
    " ### 输入：文件路径\"\"  输出：序列seq[\"\"],名称name[\"\"]\n",
    " \n",
    " - 把 sequence和名称一行一行的读取出来\n",
    " - 添加index（序列最长定为25）\n",
    " - 文件中会有空行，去除空行\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b429904e-2532-4837-a8f7-4787efd28d16",
   "metadata": {},
   "source": [
    "## 读取文件的类型 ： 读取名字和对应结合度，选取最高的结合度\n",
    "\n",
    "excel 表格 sheet “result”\n",
    "\n",
    "miR-4755-3p.pdb\t3\t-7.6\n",
    "\n",
    "miR-8055.pdb\t3\t-7.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3cceae7-329f-4efd-abc6-1810a0e2fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_affinity(file):\n",
    "    # 读取文件\n",
    "    sheet = pds.read_excel(file, sheet_name='result')\n",
    "    # 选取结合度所在的行\n",
    "    affinity_t = sheet.value[:, 2]#不懂\n",
    "    affinity_t = [a for a in affinity_t]\n",
    "    # 读取名字所在的行\n",
    "    name_t = sheet.values[:, 0]#不懂\n",
    "    name_t = [n.split('.')[0] for n in name_t]#分割开“.”之前的元素并读取\n",
    "    affi = []#最后返回的结合度\n",
    "    name = []#最后返回的名字\n",
    "    idx_same = []\n",
    "    for i,n in enumerate(name_t):\n",
    "        #如果该名字从未出现过，将其加入到返回的名字中，并找到最大的结合度\n",
    "        if i not in idx_same:\n",
    "            affi_t = [affinity_t[i]]\n",
    "            \n",
    "            # 遍历之后的每个名字，将所有的结合度比较，并将重复名字的下标添加到idx_same中，之后便不再遍历\n",
    "            for j in range(i + 1, len(name_t)):\n",
    "                if name_t[j] == n :\n",
    "                    affi_t.append(affinity_t[j])\n",
    "                    idx_sa,e.append(j)\n",
    "            affi.append(sorted(affi_t)[0])\n",
    "            name.append(n)\n",
    "        else:\n",
    "            continue\n",
    "    return affi,name\n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb88844-67ae-4d72-9a66-33ff7e5633fa",
   "metadata": {},
   "source": [
    "### 输入：文件路径\"\" 输出：结合度affi[float],名称name[\"\"]，根据下标一一对应\n",
    "\n",
    "- 分别读取结合度所在的行和名字所在的行 返回到列表\n",
    "- 选取最高的结合度 enumerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3575e2-fe57-4e53-97cb-755e950c9b18",
   "metadata": {},
   "source": [
    "## 与上一函数一样，结合度取平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d23631-6fc6-4cfa-817c-6dee1e65cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_affinity_mean(file):\n",
    "    sheet = pds.read_excel(file, sheet_name = 'result')\n",
    "    affinity_t = sheet.values[:, 2]\n",
    "    affinity_t = [a for a in affinity_t]\n",
    "    name_t = sheet.values[:, 0]\n",
    "    name_t = [n.split('.')[0] for n in name_t]\n",
    "    num = sheet.values[:, 1]\n",
    "    num = [n for n in num]\n",
    "    affi = []\n",
    "    name = []\n",
    "    idx_same = []\n",
    "    for i, n in enumerate(name_t):\n",
    "        if i not in idx_same:\n",
    "            affi_t = [affinity_t[i]]\n",
    "            num_t = num[i]\n",
    "            for j in range(i + 1, len(name_t)):\n",
    "                if name_t[j] == n:\n",
    "                    affi_t.append(affinity_t[j])\n",
    "                    idx_same.append(j)\n",
    "                    num_t += num[j]\n",
    "            affi.append(sum(affi_t)/num_t)\n",
    "            name.append(n)\n",
    "        else:\n",
    "            continue\n",
    "    return affi, name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2f8a2-268d-4bf8-9149-63e82ece217a",
   "metadata": {},
   "source": [
    "## 读取结合度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dddad69e-0b77-4dac-9856-787c5b45ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_affinity_rich(file):\n",
    "    affinity_t = sheet.values[:, 2]\n",
    "    affinity_t = [a for a in affinity_t]\n",
    "    name_t = sheet.values[:, 0]\n",
    "    name_t = [n.split('.')[0] for n in name_t]\n",
    "    max_affi = max(affinity_t)\n",
    "    min_affi = min(affinity_t)\n",
    "    affi = []\n",
    "    name = []\n",
    "    idx_same = []\n",
    "    for i, n in enumerate(name_t):\n",
    "        if i not in idx_name:\n",
    "            affi_t = [affinity_t[i]]\n",
    "            for j in range(i + 1, len(name_t)):\n",
    "                if name_t[j] == n:\n",
    "                    affi_t.append(affinity_t[j])\n",
    "                    idx_same.append(j)\n",
    "            affi_sorted = sorted(affi_t)\n",
    "            if (affi_sorted[0]-min_affi)/(max_affi-min_affi) > 0.75:\n",
    "                for _ in range(6):\n",
    "                    for af in affi_sorted:\n",
    "                        affi.append(af)\n",
    "                        name.append(n)\n",
    "            elif (affi_sorted[0] - min_affi) / (max_affi - min_affi) < 0.25:\n",
    "                for _ in range(10):\n",
    "                    for af in affi_sorted:\n",
    "                        affi.append(af)\n",
    "                        name.append(n)\n",
    "            elif (affi_sorted[0]-min_affi)/(max_affi-min_affi) > 0.6:\n",
    "                for _ in range(2):\n",
    "                    for af in affi_sorted:\n",
    "                        affi.append(af)\n",
    "                        name.append(n)\n",
    "            elif (affi_sorted[0] - min_affi) / (max_affi - min_affi) < 0.4:\n",
    "                for _ in range(2):\n",
    "                    for af in affi_sorted:\n",
    "                        affi.append(af)\n",
    "                        name.append(n)\n",
    "            else:\n",
    "                for af in affi_sorted:\n",
    "                    affi.append(af)\n",
    "                    name.append(n)\n",
    "        else:\n",
    "            continue\n",
    "    return affi, name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454323e6-3a07-4a85-9519-608b49985571",
   "metadata": {},
   "source": [
    "    因为结合度呈正态分布，中间结合度的样本会比两边的概率大很多\n",
    "    导致训练神经网络时，会根据概率更趋于平均，所以要将结合度按正态分布饿概率进行扩充\n",
    "    使得其概率分布趋于均匀分布\n",
    "    记得在记录结合度时要同时记录名字，这样两个列表长度才一样能够一一对应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94069314-74c7-4cd8-9121-f6ef5b199ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_affinity_smooth(file):\n",
    "    \"\"\"\n",
    "        读取结合度，但是因为结合度呈正态分布，中间结合度的样本会比两边的概率大很多\n",
    "        导致训练神经网络时，会根据概率更趋于平均，所以要将结合度按正态分布饿概率进行扩充\n",
    "        使得其概率分布趋于均匀分布\n",
    "        记得在记录结合度时要同时记录名字，这样两个列表长度才一样能够一一对应\n",
    "        enrich的方式不一样\n",
    "        \"\"\"\n",
    "    sheet = pds.read_excel(file, sheet_name='result')\n",
    "    affinity_t = sheet.values[:, 2]\n",
    "    affinity_t = [a for a in affinity_t]\n",
    "    name_t = sheet.values[:, 0]\n",
    "    name_t = [n.split('.')[0] for n in name_t]\n",
    "    max_affi = max(affinity_t)\n",
    "    min_affi = min(affinity_t)\n",
    "    affi = []\n",
    "    name = []\n",
    "    idx_same = []\n",
    "    for i, n in enumerate(name_t):\n",
    "        if i not in idx_same:\n",
    "            affi_t = [affinity_t[i]]\n",
    "            for j in range(i + 1, len(name_t)):\n",
    "                if name_t[j] == n:\n",
    "                    affi_t.append(affinity_t[j])\n",
    "                    idx_same.append(j)\n",
    "            affi_sorted = sorted(affi_t)\n",
    "            if ((affi_sorted[0]-min_affi)/(max_affi-min_affi) > 0.7) | \\\n",
    "                    ((affi_sorted[0]-min_affi)/(max_affi-min_affi) < 0.35):\n",
    "                for af in affi_sorted:\n",
    "                    affi.append(af)\n",
    "                    name.append(n)\n",
    "            elif ((affi_sorted[0]-min_affi)/(max_affi-min_affi) > 0.55) | \\\n",
    "                    ((affi_sorted[0]-min_affi)/(max_affi-min_affi) < 0.45):\n",
    "                for af in affi_sorted[:len(affi_sorted) // 2]:\n",
    "                    affi.append(af)\n",
    "                    name.append(n)\n",
    "            else:\n",
    "                affi.append(sorted(affi_t)[0])\n",
    "                name.append(n)\n",
    "        else:\n",
    "            continue\n",
    "    return affi, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7743a8cc-4952-4cee-9785-edcba25ef23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_search_smooth(seq, name_seq, affi, name_affi):\n",
    "    \"\"\"\n",
    "    和上一函数一样，只是根据enrich过的结果生成对应关系\n",
    "    \"\"\"\n",
    "    seq_res = []\n",
    "    affi_res = []\n",
    "    name_res = []\n",
    "    name_t = [n for n in name_seq if n in name_affi]\n",
    "    for name in name_t:\n",
    "        idx = [i for i, v in enumerate(name_affi) if v == name]\n",
    "        for i in idx:\n",
    "            name_res.append(name)\n",
    "            seq_res.append(seq[name_seq.index(name)])\n",
    "            affi_res.append(affi[i])\n",
    "\n",
    "    return seq_res, affi_res, name_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "970c6543-9718-42f4-b5e2-ceb90432ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mi(seq_file, affi_file):\n",
    "    affi, name_affi = load_affinity(affi_file)\n",
    "    seq, name_seq = load_sequence(seq_file)\n",
    "    seq_res, affi_res, name_res = cross_search(seq, name_seq, affi, name_affi)\n",
    "    return seq_res, affi_res, name_res\n",
    "\n",
    "\n",
    "def load_mi_mean(seq_file, affi_file):\n",
    "    affi, name_affi = load_affinity_mean(affi_file)\n",
    "    seq, name_seq = load_sequence(seq_file)\n",
    "    seq_res, affi_res, name_res = cross_search(seq, name_seq, affi, name_affi)\n",
    "    return seq_res, affi_res, name_res\n",
    "\n",
    "\n",
    "def load_mi_smooth(seq_file, affi_file):\n",
    "    affi, name_affi = load_affinity_smooth(affi_file)\n",
    "    seq, name_seq = load_sequence(seq_file)\n",
    "    seq_res, affi_res, name_res = cross_search_smooth(seq, name_seq, affi, name_affi)\n",
    "    return seq_res, affi_res, name_res\n",
    "\n",
    "\n",
    "def load_mi_rich(seq_file, affi_file):\n",
    "    affi, name_affi = load_affinity_rich(affi_file)\n",
    "    seq, name_seq = load_sequence(seq_file)\n",
    "    seq_res, affi_res, name_res = cross_search_smooth(seq, name_seq, affi, name_affi)\n",
    "    return seq_res, affi_res, name_res\n",
    "\n",
    "\n",
    "def load_pi(addr):\n",
    "    with open(addr, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    data = [line for line in lines if line != '\\n']\n",
    "    seq = data[1::2]\n",
    "    seq = [s.strip() for s in seq]\n",
    "    name = data[0::2]\n",
    "    name = [s.strip().split('|')[0] for s in name]\n",
    "    name_pi = []\n",
    "    for n in name:\n",
    "        if n not in name_pi:\n",
    "            name_pi.append(n)\n",
    "    seq_pi = [seq[name.index(n)] for n in name_pi]\n",
    "    return seq_pi, name_pi\n",
    "\n",
    "\n",
    "def check(seq, affi, name):\n",
    "    with open('homo-miRNA.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    data = [line for line in lines if line != '\\n']\n",
    "    seq_lines = data[1::2]\n",
    "    name_lines = data[0::2]\n",
    "    sheet = pds.read_excel('original.xls', sheet_name='result')\n",
    "    affinity_t = sheet.values[:, 2]\n",
    "    affinity_t = [a for a in affinity_t]\n",
    "    name_t = sheet.values[:, 0]\n",
    "    name_t = [n.split('.')[0] for n in name_t]\n",
    "    if (affi == affinity_t[name_t.index(name+'.pdb')]) & (seq == seq_lines[name_lines.index(name)]):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61afcebb-e850-4773-a0db-925a3a02c8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades = [70, 100, 97, 70, 85, 100, 400, 200, 32]\n",
    "grades.index(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1286e04d-7037-4b9f-88da-fe14d8a2dea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades.index(100,3,8)#搜素索引3到索引8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97739b7-7f75-49c3-baf3-f4b1a9341de3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e916cee2b9d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'seq' is not defined"
     ]
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f49c37-7428-4849-984f-e396ea2533a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
